# utils/ocr_utils.py

import easyocr
from PIL import Image, ImageEnhance, ImageFilter
from selenium.webdriver.common.actions.action_builder import ActionBuilder
from selenium.webdriver.common.actions.pointer_input import PointerInput
import os
import time
import cv2
import numpy as np

# EasyOCR Reader ì´ˆê¸°í™” (í•œêµ­ì–´ + ì˜ì–´)
reader = easyocr.Reader(['ko', 'en'], gpu=False)

def tap_coordinates(driver, x, y):
    finger = PointerInput("touch", "finger")
    actions = ActionBuilder(driver, mouse=finger)
    actions.pointer_action.move_to_location(x, y)
    actions.pointer_action.pointer_down()
    actions.pointer_action.pause(0.1)
    actions.pointer_action.pointer_up()
    actions.perform()

def take_screenshot(driver, name):
    path = f"./reports/screenshots/{name}.png"
    os.makedirs(os.path.dirname(path), exist_ok=True)
    driver.save_screenshot(path)
    print(f"ğŸ“¸ ìŠ¤í¬ë¦°ìƒ· ì €ì¥ë¨: {path}")
    return path


def preprocess_image(image_path):
    """ì´ë¯¸ì§€ë¥¼ í‘ë°± ë° ëŒ€ë¹„ ë³´ì • ë“±ìœ¼ë¡œ ì „ì²˜ë¦¬"""
    image = Image.open(image_path)
    image = image.convert("L")  # í‘ë°±
    image = image.filter(ImageFilter.SHARPEN)  # ì„ ëª…í•˜ê²Œ
    enhancer = ImageEnhance.Contrast(image)
    image = enhancer.enhance(2.0)  # ëŒ€ë¹„ ì¦ê°€
    return image

import numpy as np

def extract_text_easyocr(image_path, crop_area=None):
    """
    EasyOCRë¡œ í…ìŠ¤íŠ¸ ì¶”ì¶œ (PIL â†’ numpyë¡œ ë³€í™˜)
    """
    image = preprocess_image(image_path)
    if crop_area:
        image = image.crop(crop_area)
    
    np_image = np.array(image)  # âœ… numpyë¡œ ë³€í™˜

    result = reader.readtext(np_image, detail=0, paragraph=True)
    return "\n".join(result).strip()

def is_home_screen_text(text):
    text = text.replace(" ", "").lower()
    keywords = ["í™ˆì±„ë„", "í™ˆ", "ì±„ë„", "ì±„ë…ˆ", "í˜¼ì±„ë„"]
    return any(k in text for k in keywords)


def ocr_contains_keyword(driver, keyword, shot_name="scroll_step"):
    screenshot_path = take_screenshot(driver, shot_name)
    text = extract_text_easyocr(screenshot_path)
    print(f"ğŸ“– OCR í…ìŠ¤íŠ¸ ì¶”ì¶œ ê²°ê³¼: {text}")
    return keyword in text

# def scroll_down_w3c(driver, scroll_count=5):
#     print(f"ğŸ“¥ W3C ë°©ì‹ ìŠ¤í¬ë¡¤ {scroll_count}íšŒ ìˆ˜í–‰ í›„ OCRë¡œ ë¸”ë¡ì±„ë„ íƒìƒ‰ ì‹œì‘")
#     finger = PointerInput("touch", "finger")

#     for i in range(scroll_count):
#         print(f"â†•ï¸ W3C ìŠ¤í¬ë¡¤ {i+1}/{scroll_count}")
#         actions = ActionBuilder(driver, mouse=finger)
#         actions.pointer_action.move_to_location(500, 1800)  # ì•ˆì „í•œ ì•„ë˜ ìœ„ì¹˜
#         actions.pointer_action.pointer_down()
#         actions.pointer_action.pause(0.3)
#         actions.pointer_action.move_to_location(500, 630)   # ì¤‘ê°„ê¹Œì§€ ìŠ¤ì™€ì´í”„
#         actions.pointer_action.pointer_up()
#         actions.perform()
#         time.sleep(1.5)

def scroll_down_w3c(driver, scroll_count=5):
    print(f"ğŸ“¥ ì‚¬ìš©ì ì§€ì • ìŠ¤í¬ë¡¤ ì¢Œí‘œë¡œ {scroll_count}íšŒ ìŠ¤í¬ë¡¤ ìˆ˜í–‰")
    finger = PointerInput("touch", "finger")

    # ì§ì ‘ ì§€ì •í•œ ì•ˆì • ì¢Œí‘œ
    start_x, start_y = 403, 1953
    end_x, end_y = 361, 412

    for i in range(scroll_count):
        print(f"â†•ï¸ W3C ìŠ¤í¬ë¡¤ {i+1}/{scroll_count}: ({start_x},{start_y}) â†’ ({end_x},{end_y})")

        actions = ActionBuilder(driver, mouse=finger)
        actions.pointer_action.move_to_location(start_x, start_y)
        actions.pointer_action.pointer_down()
        actions.pointer_action.pause(0.4)  # íƒ­ ì˜¤ì¸ ë°©ì§€
        actions.pointer_action.move_to_location(end_x, end_y)
        actions.pointer_action.pause(0.4)  # ì´ë™ í›„ ì•ˆì •ì„± í™•ë³´
        actions.pointer_action.release()
        actions.perform()

        time.sleep(2.0)  # ë Œë”ë§ ì—¬ìœ 


def tap_text_by_ocr(driver, keywords, screenshot_name="ocr_target_search"):
    """
    í™”ë©´ì—ì„œ OCRë¡œ ì—¬ëŸ¬ í›„ë³´ í‚¤ì›Œë“œ ì¤‘ í•˜ë‚˜ë¥¼ ì°¾ì•„ í•´ë‹¹ ìœ„ì¹˜ë¥¼ íƒ­í•¨
    :param driver: Appium driver
    :param keywords: ['BLOCK_1', 'BLOCK1', 'BLOCL_1'] ë“± ë¦¬ìŠ¤íŠ¸
    :param screenshot_name: ì €ì¥í•  ìŠ¤í¬ë¦°ìƒ· ì´ë¦„
    :return: (íƒ­ ì„±ê³µ ì—¬ë¶€, OCR ì „ì²´ í…ìŠ¤íŠ¸)
    """
    path = take_screenshot(driver, screenshot_name)
    image = preprocess_image(path)
    np_image = np.array(image)

    results = reader.readtext(np_image, detail=1, paragraph=False)  # ì¢Œí‘œ í¬í•¨ ê²°ê³¼
    all_texts = []

    for (bbox, text, prob) in results:
        all_texts.append(text)
        for keyword in keywords:
            if keyword in text:
                # ì¤‘ì‹¬ ì¢Œí‘œ ê³„ì‚°
                (x1, y1), (x2, y2), (x3, y3), (x4, y4) = bbox
                center_x = int((x1 + x3) / 2)
                center_y = int((y1 + y3) / 2)
                print(f"âœ… '{text}' (ì •ë‹µ í›„ë³´ ì¤‘ '{keyword}' í¬í•¨) ìœ„ì¹˜: ({center_x}, {center_y}) â†’ í´ë¦­ ì‹œë„")
                tap_coordinates(driver, center_x, center_y)

                full_text = "\n".join(all_texts)
                print("ğŸ“ OCR ì „ì²´ ì¶”ì¶œ í…ìŠ¤íŠ¸:\n" + full_text)
                return True, full_text

    full_text = "\n".join(all_texts)
    print("âŒ ì–´ë–¤ ì •ë‹µ í‚¤ì›Œë“œë„ OCRì—ì„œ ì°¾ì§€ ëª»í•¨")
    print("ğŸ“ OCR ì „ì²´ ì¶”ì¶œ í…ìŠ¤íŠ¸:\n" + full_text)
    return False, full_text
    